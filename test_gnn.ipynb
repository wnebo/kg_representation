{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d78832",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'faiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfaiss\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'faiss'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.nn import GATConv\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8439a8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "PyTorch Geometric is ready!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import SAGEConv\n",
    "print(\"PyTorch Geometric is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4de6bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… æˆåŠŸåˆ›å»º entities.csv å’Œ relations.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# åˆ›å»ºå®ä½“æ•°æ®\n",
    "entities = [\n",
    "    {\"entity_name\": \"Apple\", \"type\": \"Company\", \"description\": \"A technology company known for iPhones and MacBooks.\"},\n",
    "    {\"entity_name\": \"Steve Jobs\", \"type\": \"Person\", \"description\": \"The co-founder of Apple.\"},\n",
    "    {\"entity_name\": \"iPhone\", \"type\": \"Product\", \"description\": \"A smartphone product line developed by Apple.\"},\n",
    "    {\"entity_name\": \"Tim Cook\", \"type\": \"Person\", \"description\": \"The CEO of Apple after Steve Jobs.\"},\n",
    "    {\"entity_name\": \"MacBook\", \"type\": \"Product\", \"description\": \"A line of laptop computers developed by Apple.\"},\n",
    "]\n",
    "\n",
    "# åˆ›å»ºå…³ç³»æ•°æ®\n",
    "relations = [\n",
    "    {\"source\": \"Steve Jobs\", \"target\": \"Apple\", \"description\": \"Steve Jobs co-founded Apple in 1976 and helped it become a global brand\"},\n",
    "    {\"source\": \"Apple\", \"target\": \"iPhone\", \"description\": \"Apple released the first iPhone in 2007, revolutionizing the smartphone market\"},\n",
    "]\n",
    "\n",
    "# ä¿å­˜ä¸º CSV æ–‡ä»¶\n",
    "entities_df = pd.DataFrame(entities)\n",
    "relations_df = pd.DataFrame(relations)\n",
    "\n",
    "entities_df.to_csv(\"entities.csv\", index=False)\n",
    "relations_df.to_csv(\"relations.csv\", index=False)\n",
    "\n",
    "print(\"âœ… æˆåŠŸåˆ›å»º entities.csv å’Œ relations.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d38400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========= Step 1: Load CSV ========= #\n",
    "entities_df = pd.read_csv('entities.csv')    # contains: entity_name, type, description\n",
    "relations_df = pd.read_csv('relations.csv')  # contains: source, target, description\n",
    "\n",
    "# Encode node names to integer IDs\n",
    "node_encoder = LabelEncoder()\n",
    "entities_df['node_id'] = node_encoder.fit_transform(entities_df['entity_name'])\n",
    "node_name_to_id = dict(zip(entities_df['entity_name'], entities_df['node_id']))\n",
    "\n",
    "# ========= Step 2: Build edge_index ========= #\n",
    "edges = []\n",
    "for _, row in relations_df.iterrows():\n",
    "    src = node_name_to_id[row['source']]\n",
    "    tgt = node_name_to_id[row['target']]\n",
    "    edges.append([src, tgt])\n",
    "edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()  # shape: [2, num_edges]\n",
    "\n",
    "# ========= Step 3: Generate node features using Sentence-BERT ========= #\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "node_descs = entities_df['description'].fillna(\"\").tolist()\n",
    "node_features = torch.tensor(model.encode(node_descs), dtype=torch.float)  # shape: [num_nodes, emb_dim]\n",
    "\n",
    "\n",
    "edge_descs = relations_df['description'].fillna(\"\").tolist()\n",
    "edge_features = model.encode(edge_descs, convert_to_tensor=True)  # shape: [num_edges, emb_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1066253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Step 4: Build PyG Data ========= #\n",
    "data = Data(\n",
    "    x=node_features.float(),  # [num_nodes, node_dim]\n",
    "    edge_index=edge_index,  # [2, num_edges]\n",
    "    edge_attr=edge_features.float()  # [num_edges, emb_dim]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff6ef975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========= Step 5: Define GraphSAGE ========= #\n",
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "model_gnn = GraphSAGE(in_channels=node_features.size(1), hidden_channels=128, out_channels=64)\n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01)\n",
    "\n",
    "class EdgeAwareGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_dim, hidden_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, edge_dim=edge_dim)\n",
    "        self.conv2 = GATConv(hidden_channels, out_channels, edge_dim=edge_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.conv1(x, edge_index, edge_attr).relu()\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        return x\n",
    "    \n",
    "model_gnn = EdgeAwareGNN(in_channels=node_features.size(1), edge_dim=edge_features.size(1), hidden_channels=128, out_channels=64)\n",
    "optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bbb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.0234\n",
      "Epoch 2, Loss: 0.0260\n",
      "Epoch 3, Loss: 0.0259\n",
      "Epoch 4, Loss: 0.0228\n",
      "Epoch 5, Loss: 0.0181\n",
      "Epoch 6, Loss: 0.0153\n",
      "Epoch 7, Loss: 0.0148\n",
      "Epoch 8, Loss: 0.0149\n",
      "Epoch 9, Loss: 0.0152\n",
      "Epoch 10, Loss: 0.0149\n",
      "Epoch 11, Loss: 0.0135\n",
      "Epoch 12, Loss: 0.0114\n",
      "Epoch 13, Loss: 0.0098\n",
      "Epoch 14, Loss: 0.0099\n",
      "Epoch 15, Loss: 0.0108\n",
      "Epoch 16, Loss: 0.0100\n",
      "Epoch 17, Loss: 0.0081\n",
      "Epoch 18, Loss: 0.0079\n",
      "Epoch 19, Loss: 0.0079\n",
      "Epoch 20, Loss: 0.0073\n"
     ]
    }
   ],
   "source": [
    "# ========= Step 6: Train GNN (unsupervised, simple) ========= #\n",
    "model_gnn.train()\n",
    "for epoch in range(20):\n",
    "    optimizer.zero_grad()\n",
    "    # out = model_gnn(data.x, data.edge_index)\n",
    "    out = model_gnn(data.x, data.edge_index, data.edge_attr)\n",
    "    loss = torch.mean(out.norm(dim=1))  # Dummy regularization loss to \"move\" weights\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ========= Step 7: Extract final embeddings ========= #\n",
    "model_gnn.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings = model_gnn(data.x, data.edge_index, data.edge_attr)\n",
    "    embeddings_np = embeddings.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6da3b8c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'faiss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ========= Step 8: Build FAISS index for retrieval ========= #\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m faiss_index \u001b[38;5;241m=\u001b[39m \u001b[43mfaiss\u001b[49m\u001b[38;5;241m.\u001b[39mIndexFlatL2(embeddings_np\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m      3\u001b[0m faiss_index\u001b[38;5;241m.\u001b[39madd(embeddings_np)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# ========= Step 9: Test search ========= #\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'faiss' is not defined"
     ]
    }
   ],
   "source": [
    "# ========= Step 8: Build FAISS index for retrieval ========= #\n",
    "faiss_index = faiss.IndexFlatL2(embeddings_np.shape[1])\n",
    "faiss_index.add(embeddings_np)\n",
    "\n",
    "# ========= Step 9: Test search ========= #\n",
    "def search(query, top_k=3):\n",
    "    query_vec = model.encode([query])\n",
    "    query_vec = torch.tensor(query_vec, dtype=torch.float)\n",
    "    with torch.no_grad():\n",
    "        query_emb = model_gnn(query_vec, data.edge_index)\n",
    "    D, I = faiss_index.search(query_emb.numpy(), top_k)\n",
    "    results = [entities_df.iloc[i]['entity_name'] for i in I[0]]\n",
    "    return results\n",
    "\n",
    "# ========= Example ========= #\n",
    "print(\"ğŸ” æŸ¥è¯¢: 'è‹¹æœå…¬å¸é¢†å¯¼äºº'\")\n",
    "print(search(\"è‹¹æœå…¬å¸é¢†å¯¼äºº\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
