Practical Optimizations to GraphRAG for Financial Documents: Three Key Improvements


Introduction
This talk focuses on making GraphRAG practical for financial documents—where reports are long and tables are abundant—so we can find the right page, retrieve the right span, and answer accurately. I present three pragmatic improvements  entered on recall and precision:

1. Question-guided sliding windows: the LLM scans the corpus with the user question in mind and returns the most relevant pages, substantially improving recall.

2. Prompt-embedded generative retriever: by embedding a generative retriever directly in the LLM prompt, we suppress retrieval noise and, in my comparisons, outperform a standard reranker.

3. page_question_index as a lightweight alternative: instead of parsing tables upfront, we only locate pages. Concretely, for each page, the LLM generates a small set of “questions this page can answer,” and we build an index from generated question → source span on that page. At query time, we first match the user question in the question space, then jump back to the linked span. This avoids table parsing while remaining efficient and explainable, and it works well because question-to-question similarity is often stronger than question-to-raw-text similarity on table-heavy pages.

Finally, at answer time, I rewrite reasoning-style questions into extraction-style prompts to further improve factual accuracy. Together, these steps yield steadier recall, lower noise, and more accurate answers on long, table-dense financial reports.

