This six-month internship was conducted at the BNP Paribas Corporate and Institutional Banking (CIB) AI Lab, focusing on enhancing the performance of Retrieval-Augmented Generation (RAG) through the GraphRAG framework. During the internship, I systematically analyzed the core mechanisms of GraphRAG and developed a recall evaluation framework using both internal and open-source datasets to assess its applicability in financial contexts. Building upon this foundation, I proposed an improved Query-Based RAG approach incorporating the concept of a Generative Retriever, significantly boosting recall and reasoning accuracy: for complex reasoning tasks on ~200-page annual reports, the system achieved an 85% probability of locating the correct page within a 5-page window. Furthermore, I designed a scalable Page-Question-Index architecture, which reduced online response time to approximately 5 minutes for processing 150 queries while substantially decreasing token consumption. Finally, by applying contrastive learning and LoRA fine-tuning to synthetic datasets, I improved embedding model recall by an additional 3â€“5%. These findings provide practical insights and technical strategies for optimizing the efficiency of RAG applications powered by LLMs in the financial domain.


During my six-month internship at BNP Paribas CIB AI Lab, I focused on enhancing RAG performance in the financial domain using GraphRAG. My work involved improving retrieval methods, optimizing response efficiency, and boosting model performance with contrastive learning and LoRA fine-tuning.
